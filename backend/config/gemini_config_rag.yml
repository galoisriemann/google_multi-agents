# Gemini LLM Configuration for RAG-Only Workflow

# Basic LLM Configuration
provider: "gemini"
model: "gemini-2.0-flash"         # Default model for RAG
temperature: 0.7
max_tokens: 1000

# API Configuration
api_config:
  api_key: "AIzaSyCs7T6qdSPA3r16W_q01fCzKZvn-5DAioI"
  timeout: 60

# Backend Configuration
backend: "google"

# Gemini-specific Generation Config
generation_config:
  top_p: 0.95
  top_k: 40
  candidate_count: 1
  stop_sequences: []
  max_output_tokens: 1000
  temperature: 0.7

# Safety Settings
safety_settings:
  - category: "HARM_CATEGORY_HARASSMENT"
    threshold: "BLOCK_MEDIUM_AND_ABOVE"
  - category: "HARM_CATEGORY_HATE_SPEECH"
    threshold: "BLOCK_MEDIUM_AND_ABOVE"
  - category: "HARM_CATEGORY_SEXUALLY_EXPLICIT"
    threshold: "BLOCK_MEDIUM_AND_ABOVE"
  - category: "HARM_CATEGORY_DANGEROUS_CONTENT"
    threshold: "BLOCK_MEDIUM_AND_ABOVE"

# Metadata
metadata:
  version: "1.0"
  description: "Gemini config for RAG agent with MCP"
  last_updated: "2024-06-04"